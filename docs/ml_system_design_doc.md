# ML System Design Doc - Рекомендация релевантной рекламы

---

## 1. Цели и предпосылки

### 1.1. Зачем идем в разработку продукта?

- **Бизнес-цель Product Owner**:  
  Платформа Avito.tech хочет повысить эффективность рекламных кампаний, предоставляя пользователям наиболее релевантные объявления. В результате этого предполагается увеличение CTR (Click-Through Rate) и улучшение ROI (Return on Investment) для рекламодателей.

- **Почему станет лучше, чем сейчас, от использования ML (Product Owner & Data Scientist)**:  
  Использование ML-моделей для предсказания вероятности клика обеспечит:
  - Персонализированные рекомендации, что повысит удовлетворенность пользователей.
  - Снижение расходов на неэффективные показы, что приведет к более высокому ROI для рекламодателей.

- **Что будем считать успехом итерации с точки зрения бизнеса (Product Owner)**:  
  Успехом будет считаться:
  - Достижение требуемой точности в предсказаниях модели (ROC AUC ≥ 0.55, значение взято исходя из анализа лидерборда соревнования на этих данных).
  - Увеличение CTR.
  - Уменьшение затрат на рекламу с учётом роста отклика пользователей.

---

### 1.2. Бизнес-требования и ограничения

- **Краткое описание БТ и ссылки на детальные документы с бизнес-требованиями (Product Owner)**:  
  Основное бизнес-требование — создание модели, предсказывающей вероятность клика по рекламному объявлению.

- **Бизнес-ограничения (Product Owner)**:  
  1. Модель должна работать с анонимизированными данными пользователей, не нарушая требования GDPR.
  2. Требования к скорости модели: предсказания должны быть сгенерированы в онлайне (за несколько десятков миллисекунд).
  3. Для первого запуска не требуется использование нейросетевых моделей, решение доложно работать без GPU.

- **Что мы ожидаем от конкретной итерации (Product Owner)**:  
  Итерация должна привести к созданию работающего прототипа модели, который будет оцениваться по метрике качества ROC-AUC. Модель должна продемонстрировать улучшение в точности предсказаний по сравнению с бейзлайном - если пользователь уже увидел и кликнул на рекламу - он кликнет снова.

- **Описание бизнес-процесса пилота (Product Owner)**:  
  Модель может быть использована в качестве модели первого уровня в общем пайплайне рекомендации рекламы для отсева кандидатов и генерации дополнительной фичи, которая поможет модели градиентного бустинга в ранжировании.

- **Что считаем успешным пилотом? Критерии успеха и возможные пути развития проекта (Product Owner)**:  
  Пилот считается успешным, если:
  - Побит порог ROC AUC ≥ 0.55.
  - A/B тестирование показало статзначимое улучшение.
  - Для работы модели не требуется GPU.

---

### 1.3. Что входит в скоуп проекта/итерации, что не входит

- **На закрытие каких БТ подписываемся в данной итерации (Data Scientist)**:  
  В рамках итерации мы закрываем создание рабочей модели для предсказания кликов на основе данных о взаимодействиях пользователей с рекламой и характеристиках рекламных кампаний. Ожидается, что модель будет обучена на исторических данных и провалидирована.

- **Что не будет закрыто (Data Scientist)**:  
  - Модели для прогнозирования других метрик (например, ROI или eCPM) в рамках текущей итерации.
  - Интеграция модели с системой показа рекламы и API в реальном времени.

- **Описание результата с точки зрения качества кода и воспроизводимости решения (Data Scientist)**:  
  - Код должен соответствовать PEP8, иметь докстринги, и проходить проверки линтеров.
  - Решение будет воспроизводимым, с использованием контейнеров (например, Docker) для упрощения развертывания модели.

- **Описание планируемого технического долга (что оставляем для дальнейшей продуктивизации) (Data Scientist)**:  
  - Интеграция модели в рабочее окружение.
  - Настройка и автоматизация обновления модели с использованием новых данных.
  - Оптимизация модели для работы в реальном времени с более низкими задержками.

---

### 1.4. Предпосылки решения

- **Описание всех общих предпосылок решения, используемых в системе – с обоснованием от запроса бизнеса (Data Scientist)**:  
  - Данные о взаимодействиях пользователей с рекламой являются достаточными для предсказания вероятности клика.
  - Модель будет прогнозировать вероятность клика на основе исторических данных за последние 3 недели.
  - Модель будет работать на заранее определенном наборе пользователей и рекламных предложений.

---

## 2. Методология

### 2.1. Постановка задачи

Мы разрабатываем рекомендательную модель, которая будет предсказывать вероятность клика на рекламное объявление для каждого пользователя на основе:
- Исторических данных о взаимодействиях пользователя с рекламой.
- Характеристик рекламной кампании (например, цель кампании, категория, и т.д.).
  
Модель будет классификационной (бинарной), где цель — предсказать, кликнет ли пользователь на рекламу (класс 1) или нет (класс 0).

---

### 2.2. Блок-схема решения

![Блок-схема](/images/block-scheme.jpg)

### 2.3. Этапы решения задачи

#### Этап 1. Подготовка данных
**Описание данных и сущностей**  
Изначально данные представляют собой parquet-файлы с таблицами, содержащими данные о взаимодействиях пользователей с рекламой и характеристиках рекламных кампаний, и представлены следующим образом:

* Основная таблица с взаимодействиями:  
platform_id: id платформы (Android, Ios и т.п.)  
user_id: id пользователя   
adv_campaign_id: id рекламной кампании   
banner_code: код баннера  
adv_creative_id: индификатор креатива  
event_date: дата показа рекламной кампании пользователю  
is_main: показ рекламы был осуществлен с главной страницы   
target: клик / не клик   

* Категории:  
microcat_id: id микрокатегории   
level_id: id уровня в дереве микрокатегорий   
parent_microcat_id: id родительской микрокатегории  
logcat_id: id логической категории   
vertical_id: id вертикали   
category_id: id категории   

* Рекламные кампании:  
adv_campaign_id: id рекламной кампании  
start_date: date дата начала рекламной кампании  
end_date: date дата завершения рекламной кампании   
goal_cost: цена за клик на рекламу  
goal_budget: общий бюджет рекламной кампании   
logcat_id: id логической категории товаров из рекламной кампании  
location_ids: id локации, на которую рекламная кампания распространяется   

**Проблемы, выявленные в EDA**
* Пропуски в столбцах таблицы категорий рекламы
* Сложная иерархия категорий
* Отсутствие данных о содержании рекламных банеров
* Недостаточно подробное описание столбцов в таблицах (например, banner_code)
* Недостаточное описание терминов (вертикаль, логическая категория, микрокатегория)
* Данные представлены только за 3 недели
* Сильный дисбаланс меток классов (только 0.51% кликов)
* Возможно, потребуется использовать методы oversampling (например, SMOTE) или undersampling
* Для проведения EDA понадобилось больше 32 Гб оперативной памяти
* Большое количество данных модет потенциально привести к долгому времени обучения моделей и большим затратам оперативной памяти

**Процесс генерации данных**  
Данные были получены один раз, за первые 3 недели сентября 2024 года и были представлены на хакатоне. Повторной генерации данных не планируется.

**Объём данных**  
Данные содержат более 100M взаимодействий, 3M уникальных пользователей, 4K уникальных рекламных кампаний за 3 недели. Данного объёма должно быть достаточно для построения предсказаний на ближайшую неделю.

**Конфиденциальная информация**  
Данные анонимизированы (platform_id, user_id, adv_campaign_id, banner_code, adv_creative_id) и не нарушают требования GDPR.

**Необходимый результат этапа**
1. Изучение данных и выявление проблем:
   - Анализ распределений целевой переменной и основных фичей.
   - Проверка наличия выбросов.
   - Выявление коллинеарных признаков и потенциально избыточных фичей.
2. Нахождение потенциально важных признаков:
   - Исследование корреляций между признаками и целевой переменной.
   - Генерация сводных статистик (например, CTR для разных категорий, платформ, и дней недели).
3. Очистка данных от пропусков и дубликатов:
   - Удаление или заполнение пропусков (например, средними, медианами).
   - Удаление или корректировка дубликатов в данных.
4. Объединение данных в единую таблицу:
   - Слияние таблиц Train/Test, Campaigns, и Categories.
   - Проверка корректности связей между user_id, adv_campaign_id, и другими идентификаторами.
5. Создание новых признаков:
   - Генерация временных фичей (например, день недели, праздничный день).
   - Создание агрегированных признаков (например, средний CTR пользователя или кампании).
6. Создание необходимых скриптов для преобразования данных:
   - Разработка функций или классов для автоматизации обработки данных.
   - Сохранение пайплайна обработки данных для дальнейшего использования.
7. Оптимизация типов данных:
   - Приведение данных к более экономным типам (float32, int16, и т.д.).
   - Сокращение потребления памяти при загрузке данных.


#### Этап 2. Подготовка прогнозных моделей
##### ML-метрики и функции потерь

**Для бинарной классификации:**
- **ROC AUC**: Подходит для оценки качества классификации, особенно в условиях дисбаланса классов, позволяет оценить модель при разных порогах.
- **Precision, Recall и F1-score**: Полезны для разносторонней оценки качества классификации.
- **Weighted Binary Crossentropy**: Учитывает дисбаланс классов, задавая больший вес для меньшего класса.

**Для ранжирования:**
- **NDCG (Normalized Discounted Cumulative Gain)**: Учитывает положение релевантных элементов в списке, назначая больший вес верхним позициям. Это особенно важно в рекламных системах, где верхние позиции получают больше кликов. По сравнению с MAP, NDCG штрафует за неправильный порядок релевантных элементов, что делает её предпочтительной для задач с критичной важностью топовых позиций.
- **MRR (Mean Reciprocal Rank)**: Фокусируется на нахождении первого релевантного элемента, что полезно в задачах, где важен только первый клик. Однако она игнорирует качество остальных позиций, что делает её менее универсальной, чем NDCG.
- **MAP (Mean Average Precision)**: Эта метрика оценивает среднюю точность рекомендаций на всех позициях, но не учитывает их относительную важность (в отличие от NDCG).

**Функции потерь для ранжирования:**
- **LambdaRank Loss**: Учитывает относительную важность позиций в списке и оптимизирует NDCG, что делает его идеальным для задач с критичным значением топовых позиций.
- **Listwise функции потерь**: Оптимизируют весь список целиком, а не отдельные пары. Это делает его подходящим для сложных задач ранжирования, но увеличивает вычислительные затраты, что может быть ограничением при больших наборах данных.

##### Схема ML-валидации
- Данные разделяются на тренировочную и тестовую выборки по времени (`train` - первые 80%, `test` - последние 20%). При необходимости использования валидационной выборки (например, для подбора гиперпараметров), можно использовать следующее разбиение: train - 70%, val - 15%, test - 15%.

##### Структура бейзлайна
**Бейзлайн без ML:**
- Предположение: пользователь кликнет на ту же рекламу, на которую он кликал ранее. Результаты сравниваются с ML-моделями.

**ML-модель для пилота:**
- **Модель**: Gradient Boosting (например, CatBoost, LightGBM, XGBoost).
- **Особенности**:
  - Применение взвешенной функции потерь для корректировки дисбаланса
  - Использование агрегированных данных из таблиц + дополнительные фичи из feature engineering

##### Дальнейшее усовершествование системы
**Система с ранжированием:**
- **Использование двухуровневого подхода**:
  - **Модели первого уровня (пример)**:
    - EASE
    - LightFM
    - SVD
    - iALS
    - User/Item KNN
  - **Модель второго уровня**:
    - Gradient Boosting (например, LightGBM), использующий предсказания моделей первого уровня как фичи, а также дополнительные признаки из данных.

Нейросетевые модели не рассматриваются на данном этапе, так как изначально был запрос на модель, не использующую GPU.

##### Стратегии развития системы:
- Улучшение ранжирования через интеграцию информации о категориях товаров и пользовательских предпочтений.
- Использование pre-trained моделей или векторных представлений контента.
- Использование нейросетевых моделей для ранжирования (таких как SASRec, BERT4Rec, VAE, PinFormer) и/или классификации.
- Исследование общих предпочтений пользователей и краткосрочных трендов. Адаптация трансформерной модели под это (Как в KuaiFormer).

##### Необходимый результат этапа
- Модель, достигающая порога качества ROC AUC ≥ 0.55.

#### Этап 3. Важность признаков, интерпретируемость модели
- Выявление наиболее значимых признаков с использованием методов SHAP, Permutation Importance или Gini Importance (для моделей на основе деревьев).
- Оценка влияния каждого признака на предсказания модели, создание отчетов для бизнес-команды.
- Валидация важности признаков через удаление/добавление фичей и измерение изменения метрик качества.

#### Этап 4. Улучшение моделей, тюнинг гиперпараметров
- Проведение гиперпараметрической оптимизации, например, с использованием Optuna.
- Эксперименты с различными экспериментальными архитектурами системы (трансформеры на последнем уровне или LLM для выбора категории рекламы чтобы повысить diversity).
- Тестирование новых стратегий feature engineering, добавление новых и удаление избыточных фичей.
- Анализ устойчивости модели к изменению данных, изучение возможного переобучения.
- Оптимизация модели для работы в реальном времени с более низкими задержками.
- Анализ устойчивости модели для обучения на меньшем количестве данных.

#### Этап 5. Создание ML-сервиса и его тестирование
- Разработка API для инференса модели с использованием FastAPI или Flask.
- Контейнеризация сервиса с Docker, настройка CI/CD пайплайнов.
- Тестирование производительности сервиса в условиях высокой нагрузки.
- Настройка мониторинга предсказаний и логирования ошибок.

#### Этап 6. Автоматизация процесса обучения и обновления модели
- Настройка Airflow для автоматизации обучения модели по расписанию.
- Интеграция MLOps-инструментов, таких как MLflow, для управления экспериментами и версиями моделей.
- Валидация качества обновленных моделей перед их деплоем.

#### Этап 7. Закрытие технического долга
- Оптимизация кода для снижения затрат вычислительных ресурсов.
- Документирование всех компонентов системы, создание гайдлайнов для будущих разработчиков.
- Устранение выявленных технических проблем (например, долгой обработки данных или избыточного потребления памяти).

### 3. Подготовка пилота

#### 3.1. Методология оценки пилота

##### Цели пилота
Основная цель пилота — оценить, насколько предложенная ML-модель классификации улучшает метрики качества предсказаний кликов (CTR) и удовлетворяет бизнес-ограничения. Дополнительно необходимо подтвердить, что модель корректно интегрируется в текущую инфраструктуру и не приводит к ухудшению системных характеристик.

##### Офлайн-оценка
- **Цель:** Провести сравнение предложенной модели с бейзлайном на новых свежих исторических данных, не представленных до этого в обучающей, валидационной, тестирующей выборках.
- **Метод:** 
  - Использовать данные о взаимодействиях пользователей за последние три недели для обучения и тестирования модели.
  - Оценить качество модели с использованием ROC AUC, Precision и Recall.
  - Проверить производительность модели по времени инференса и использованию памяти на выделенных серверах.

##### Онлайн-оценка (A/B тестирование)
- **Цель:** Оценить реальное влияние модели на ключевые метрики в условиях продакшена.
- **Исполнение:** 
  - Тестирование будет проводиться силами команды платформы A/B тестирования.
  - Перед запуском A/B теста требуется:
    1. Разработать дизайн эксперимента, включая разбиение пользователей на пилотную и контрольную группы с использованием методов стратификации.
    2. Рассчитать минимально необходимый размер выборки на основе текущего CTR (0.51%) и минимально детектируемого эффекта (например, 0.04%) для достижения статистической значимости при мощности теста 80% и уровне значимости 5%.
    3. Определить оптимальную продолжительность тестирования, учитывая сезонные колебания и достаточность объема данных.
    4. Провести A/A тест для проверки корректности разбиения пользователей и расчета уровня ошибок I и II рода, а также для определения возможных инфраструктурных ограничений (например, затрат на обработку данных).
  - Логировать данные о взаимодействиях пользователей в обеих группах для последующего анализа.

#### 3.2. Критерии успешности пилота

1. **Качество классификации:**
   - ROC AUC модели ≥ 0.55 на данных пилотной группы.
   - Увеличение CTR в пилотной группе по сравнению с контрольной при статистически значимом уровне (95% доверительный интервал, мощность теста 80%).
   - Стабильные Precision и Recall.

2. **Системная стабильность:**
   - Время отклика модели остается в пределах оговоренных ограничений (несколько десятков миллисекунд).
   - Использование ресурсов (памяти, CPU) не превышает допустимых значений.

3. **Дополнительные критерии успеха:**
   - Техническая инфраструктура позволяет масштабировать решение для 100% пользователей без необходимости значительных доработок.
   - Логирование и мониторинг успешно фиксируют данные и позволяют оперативно реагировать на инциденты.
   - ROI от применения модели достигается в ожидаемый срок.

#### 3.3. Схема пилота

1. **Подготовка инфраструктуры:**
   - Настроить логирование пользовательских взаимодействий, обеспечив обработку не менее 10% текущего трафика (~3M событий в день). 
   - Учесть фиксированный лимит в 100 RPS и latency 500-1000ms, что позволяет обрабатывать указанный объем событий. Если текущая инфраструктура окажется недостаточной, возможны изменения размера групп или длительности теста.
   - Проверить готовность систем к обработке пилотной нагрузки через A/A тест.

2. **Проведение A/B теста:**
   - Пилотная группа использует предсказания новой модели.
   - Контрольная группа остается на текущем бейзлайне (например, правило повторного клика).
   - Сбор данных о метриках (CTR, Precision, Recall, системная нагрузка) для обеих групп.

3. **Логирование и анализ:**
   - Логировать события в режиме реального времени.
   - Провести анализ различий между группами, используя доверительные интервалы, гипотезы о равенстве средних и дополнительные статистические методы.

4. **Итерационный цикл:**
   - На основе результатов A/B теста:
     - Провести анализ ошибок модели и уточнить её архитектуру или гиперпараметры.
     - Подготовить рекомендации для продуктивизации в случае успеха или корректировок в случае неудачи.

#### 3.4. Следующие шаги в зависимости от исхода пилота

1. **В случае успеха:**
   - Продуктивизация модели и расширение её применения на весь трафик.
   - Автоматизация процесса обновления и дообучения модели.
   - Оптимизация инфраструктуры для работы с полной нагрузкой.
   - Улучшение модели с помощью методов, описанных в этапе 2 (Подготовка прогнозных моделей).

2. **В случае неудачи:**
   - Провести анализ ошибок (как в данных, так и в предсказаниях модели).
   - При необходимости доработать модель, повторить пилотный запуск с обновленными параметрами или другой архитектурой решения.
   - Если повторный запуск также не приведет к успеху, рассмотреть альтернативные подходы к решению

## 4. Внедрение

### 4.1. Архитектура решения

#### Диаграмма архитектуры:

![Диаграмма ML-сервиса](/images/ml_service_architecture_diagram.png)

#### Описание компонентов:

- **FastAPI**: Главный сервис инференса, отвечающий за маршрутизацию запросов и взаимодействие с моделью.
- **Gunicorn**: Cервер WSGI, распределяющий запросы между воркерами. Обладает встроенным балансировщиком нагрузки.
- **MLFlow**: Система управления жизненным циклом моделей (трекинг экспериментов, сохранение и обновление моделей).
- **Minio**: Хранилище артефактов (модели, графики, метрики).
- **PostgreSQL**: База данных для мета-информации.

#### Формат запроса и ответа
```json
{
    "data": [
        {
            "user_id": 120738,
            "adv_campaign_id": 195,
            "platform_id": 2,
            "adv_creative_id": 3267,
            "event_date": "2024-09-21T00:00:00",
            "banner_code": 8,
            "is_main": true,
            "dayofweek": 5,
            "is_weekend": 1,
            "end_date": "2024-09-27T00:00:00",
            "days_to_campaign_end": 6,
            "is_campaign_early": false,
            "user_click_rate": 0.01418,
            "user_impressions_count": 141,
            "user_campaign_diversity": 67,
            "campaign_ctr": 0.007122,
            "campaign_impressions": 13760,
            "campaign_budget_per_day": 576.5,
            "logcat_id": 65,
            "creative_click_rate": 0.007122,
            "creative_impressions": 13760,
            "banner_click_rate": 0.005474,
            "banner_impressions": 74296252,
            "platform_ctr": 0.006027,
            "microcat_popularity": 551,
            "parent_microcat_count": 93,
            "user_campaign_interaction_rate": 0.0
        },
        ...
    ]
}
```

```json
{
    "predictions": [
        0.0,
        ...
    ]
}
```

---

### 4.2. Описание инфраструктуры и масштабируемости

#### Текущая инфраструктура:

- **Docker Compose**: Все сервисы развёрнуты в изолированных контейнерах, что обеспечивает модульность и гибкость.
- **FastAPI + Gunicorn**: Поддерживает 4 реплики воркеров, которые справляются с текущей нагрузкой в 262.7 RPS при медианной задержке 11 мс.
- **MLFlow + Minio + PostgreSQL**: Позволяет эффективно управлять версиями моделей.

#### Преимущества:
1. **Гибкость**: Использование контейнеров позволяет быстро масштабировать и добавлять новые компоненты.
2. **Управляемость**: MLFlow обеспечивает централизованный контроль версий моделей и экспериментов.
3. **Масштабируемость**: Gunicorn позволяет увеличивать количество воркеров при повышении нагрузки.

#### Недостатки:
1. **Сложность**: Необходимость управления большим количеством контейнеров.
2. **Ограничения Gunicorn**: Возможна проблема с масштабированием при росте нагрузки выше 1000 RPS.

#### Масштабирование:
- **Горизонтальное**: Добавление новых реплик воркеров Gunicorn.
- **Вертикальное**: Увеличение доступных ресурсов (CPU, RAM) на текущих узлах.
- **Кеширование**: Использование Redis или Memcached для хранения часто запрашиваемых результатов инференса.
- **Балансировка нагрузки**: Внедрение Nginx перед Gunicorn для более эффективного распределения трафика (позволяет распределять нагрузку на нескольких машинах).

#### Стресс-тестирование с использованием Locust:
- **Цель**: Оценить производительность системы под высокой нагрузкой.
- **Метод**: Locust использовался для генерации запросов к сервису инференса с различной интенсивностью (RPS).
- **Результаты**:
  - Средняя задержка при нагрузке 262.7 RPS: 14.91 мс.
  - 95-й перцентиль задержек: 34 мс.
  - Максимальная нагрузка: 300 RPS без существенного увеличения времени отклика.
- **Выводы**: Текущая инфраструктура выдерживает заявленные требования SLA.
![Диаграмма ML-сервиса](/images/locust.png)
---

### 4.3. Требования к работе системы (SLA)

- **Пропускная способность**:
  - Максимальная нагрузка: 200 RPS.

- **Задержки**:
  - Медианная: 100 мс.
  - 95-й перцентиль: 300 мс.
  - 99-й перцентиль: 500 мс.

---

### 4.4. Безопасность системы

- **Потенциальные уязвимости**:
  - Атаки на API (например, DDoS).
  - Утечка данных при неправильно настроенном доступе к Minio, PostgreSQL или MLFlow.

- **Меры защиты**:
  - Ограничение RPS на уровне API (Rate Limiting).
  - Использование HTTPS для шифрования трафика.
  - Регулярное обновление контейнеров с устранением известных уязвимостей.

---

### 4.5. Безопасность данных

- **Соответствие GDPR**:
  - Данные пользователей анонимизированы.
  - Логи запросов не содержат персональной информации.
  - Обработка данных соответствует принципу минимизации (только необходимые данные).

---

### 4.6. Издержки

- **Ресурсы**:
  - CPU: 1 ядро 2.4+ ГГц на воркер Gunicorn.
  - RAM: ~2 ГБ на воркер Gunicorn.
  - ROM: 30 Гб.

- **Ориентировочная стоимость**:
  - AWS EC2 (2 x m5.large): ~$70 в месяц.
  - S3-хранилище Minio: ~$50 в месяц.
  - PostgreSQL: ~$50 в месяц.

Итого: ~$170 в месяц.

---

### 4.7. Integration points

- **External systems — FastAPI**:
  - Метод: REST API.
  - Назначение: Получение предсказаний.

- **FastAPI — MLFlow**:
  - Метод: HTTP-запросы.
  - Назначение: Загрузка последней версии модели.

- **MLFlow — PostgreSQL**:
  - Метод: SQL-запросы.
  - Назначение: Получение метаданных о моделях.

- **MLFlow — Minio**:
  - Метод: S3 API.
  - Назначение: Хранение артефактов моделей.

---

### 4.8. Риски

- **Риски масштабирования**:
  - Ограничение Gunicorn на уровне нагрузки выше 1000 RPS.
  - Узкие места в производительности PostgreSQL или Minio.

- **Риски инфраструктуры**:
  - Потенциальные сбои контейнеров Docker.
  - Ошибки при обновлении модели через MLFlow.

- **Неопределённости**:
  - Рост числа запросов выше запланированных значений.
  - Низкая производительность новых моделей.
  - Изменение формата и объёма данных.

**Меры снижения рисков**:
- Регулярное стресс-тестирование.
- Настройка мониторинга ресурсов (Prometheus, Grafana).
- Логирование.
- Бэкапы.
